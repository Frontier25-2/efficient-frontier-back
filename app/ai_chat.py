# app/ai_chat.py
import os
from flask import Blueprint, request, jsonify, abort
import google.generativeai as genai

bp_ai = Blueprint("ai_chat", __name__)

# Gemini ëª¨ë¸ ì´ˆê¸°í™”
api_key = os.getenv("GEMINI_API_KEY")
gemini_model = None

if api_key:
    try:
        genai.configure(api_key=api_key)
        gemini_model = genai.GenerativeModel(
            model_name='gemini-2.0-flash',
            system_instruction="ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ AI ìì‚°ë°°ë¶„ ë¶„ì„ ë„ìš°ë¯¸ì…ë‹ˆë‹¤."
        )
        print("âœ… Gemini ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ (ai_chat.py)")
    except Exception as e:
        print(f"ğŸš¨ Gemini ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
else:
    print("ğŸš¨ GEMINI_API_KEY ì—†ìŒ. .env íŒŒì¼ í™•ì¸ í•„ìš”.")


# /chat ì—”ë“œí¬ì¸íŠ¸
@bp_ai.post("/chat")
def handle_chat():
    data = request.get_json(silent=True) or {}
    user_message = (data.get("message") or "").strip()

    if not user_message:
        abort(400, "message is required")

    if not gemini_model:
        abort(503, "AI service not available")

    try:
        response = gemini_model.generate_content(user_message)
        return jsonify({"reply": response.text})
    except Exception as e:
        print(f"AI error: {e}")
        abort(500, "Error processing AI response")
